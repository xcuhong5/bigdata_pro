<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <!-- NameNode 数据存储目录; 引用core-site.xml 的hadoop.tmp.dir -->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file://${hadoop.tmp.dir}/name</value>
    </property>
    <!-- DataNode 数据存储目录 -->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file://${hadoop.tmp.dir}/data</value>
    </property>
    <!-- JournalNode 数据存储目录 -->
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>${hadoop.tmp.dir}/jn</value>
    </property>
    <!-- 完全分布式集群名称 -->
    <property>
        <name>dfs.nameservices</name>
        <value>hdpcluster</value>
    </property>
    <!-- 集群中 NameNode 节点都有哪些; 就是下面 三个参数 -->
    <property>
        <name>dfs.ha.namenodes.hdpcluster</name>
        <value>nn1,nn2,nn3</value>
    </property>
    <!-- NameNode 的 RPC 内部通信地址 -->
    <property>
        <name>dfs.namenode.rpc-address.hdpcluster.nn1</name>
        <value>hdp180:8020</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.hdpcluster.nn2</name>
        <value>hdp181:8020</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.hdpcluster.nn3</name>
        <value>hdp182:8020</value>
    </property>
    
    <!-- NameNode 的 http web通信地址 -->
    <property>
        <name>dfs.namenode.http-address.hdpcluster.nn1</name>
        <value>hdp180:9870</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.hdpcluster.nn2</name>
        <value>hdp181:9870</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.hdpcluster.nn3</name>
        <value>hdp182:9870</value>
    </property>
    
    <!-- 指定 NameNode 元数据在 JournalNode 上的存放位置 -->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://hdp180:8485;hdp181:8485;hdp182:8485/hdpcluster</value>
    </property>
    <!-- 访问代理类： client 用于确定哪个 NameNode 为 Active -->
    <property>
        <name>dfs.client.failover.proxy.provider.hdpcluster</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <!-- 配置隔离机制，即同一时刻只能有一台服务器 NN 对外响应 -->
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>
	sshfence
	shell(/bin/true)
	</value>
    </property>
    <!-- 使用隔离机制时需要 ssh 秘钥登录-->
    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/xc/.ssh/id_rsa</value>
    </property>
    
    <!-- 启用 nn 故障自动转移 -->
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
    <!-- spark  身份权限 检查 关闭 hdfs-site.xml -->
    <property>
     <name>dfs.permissions.enabled</name>
     <value>false</value>
   </property>
</configuration>

